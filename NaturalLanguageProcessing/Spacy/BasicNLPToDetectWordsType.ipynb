{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'es_core_news_sm'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mspacy\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mes_core_news_sm\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mes_core_news_md\u001B[39;00m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'es_core_news_sm'"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import es_core_news_sm\n",
    "import es_core_news_md"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Aqui lo que hacemos es tokenizar un texto, es decir, lo que hacemos es separar el texto por tokens/palabras, obtenido la palbra, su lemma y el tipo de palabra que es un nombre,pronombre etc..., para detectar las palabras usamos el core que hemos descargado de spacy llamado es_core_news_sm\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nlp = es_core_news_sm.load()\n",
    "\n",
    "doc = nlp('''Un desastroso espirítu posee tu tierra:\n",
    "            donde la tribu unida blandió sus mazas,\n",
    "            hoy se enciende entre hermanos perpetua guerra,\n",
    "            se hieren y destrozan las mismas razas.''')\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, \"|\", token.lemma_, '|', token.pos_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Una vez analizado el texto se crea un documento analizado. Para poderlos visualizar los árboles de dependencias estructural pueden ser utilizados para realizar discriminadores de palabras utiles\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "from IPython.display import SVG\n",
    "\n",
    "doc = nlp(\"Jose Ayerdis es un desarrollador que trabaja en procesamiento de lenguaje natural, con una maestria en Universidad de Buffalo, Nueva York.\")\n",
    "\n",
    "SVG(data = displacy.render(doc))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Aqui lo que hacemos es reconocer y mostrar entidades de valor dentro del texto\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nlp_md = es_core_news_md.load()\n",
    "article_text = '''La ONG Fundación del Río explicó este viernes que la decisión de la Organización de la ONU para la Educación, la Ciencia y la Cultura (Unesco) de declarar como geoparque el río Coco, ubicado en el norte de Nicaragua, obliga a las autoridades nicaragüenses a proteger su ecosistema, ya que se encuentra en el área más deforestada de la cuenca. La Unesco está reconociendo la importancia del río Coco, pero también está haciendo un llamado al Gobierno a que actúe en la protección y la conservación de esos ecosistemas, dijo a Efe el presidente de la Fundación del Río, Amaru Ruiz.'''\n",
    "doc = nlp_md(article_text)\n",
    "SVG(data = displacy.render(doc, style=\"ent\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Similutud de palabras\n",
    "Podemos utilizar la librería para saber la similitud de las palabras, eso se lleva a cabo por grupos de significado y el algoritmo puede darnos un porcentaje de relevancia para cada valor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nlp_md = es_core_news_md.load()\n",
    "tokens = nlp_md(\"perro gato banana manzana rey reina\")\n",
    "\n",
    "for token1 in tokens:\n",
    "    for token2 in tokens:\n",
    "        print(token1.text, token2.text, token1.similarity(token2))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# A2, analizar sintacticamente estar oraciones\n",
    " El gato come pescado.\n",
    " Juan lee un libro interesante.\n",
    " El niño juega con su pelota roja.\n",
    " Ella canta en la ducha.\n",
    " Yo escribo un correo electrónico."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "from IPython.display import SVG\n",
    "\n",
    "doc = nlp(\"El gato come pescado.\")\n",
    "\n",
    "SVG(data = displacy.render(doc))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "doc = nlp(\"Juan lee un libro interesante.\")\n",
    "\n",
    "SVG(data = displacy.render(doc))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "doc = nlp(\" El niño juega con su pelota roja.\")\n",
    "\n",
    "SVG(data = displacy.render(doc))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "doc = nlp(\"Ella canta en la ducha.\")\n",
    "\n",
    "SVG(data = displacy.render(doc))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "doc = nlp(\"Yo escribo un correo electrónico.\")\n",
    "\n",
    "SVG(data = displacy.render(doc))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
